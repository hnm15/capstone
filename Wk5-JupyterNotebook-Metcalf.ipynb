{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DX799S O1 Data Science Capstone (Summer 1 2025): ACTIVITY 5.2 ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each week, you will apply the concepts of that week to your Integrated Capstone Projectâ€™s dataset. In preparation for Milestone One, create a Jupyter Notebook (similar to in Module B, Semester Two) that illustrates these lessons. There are no specific questions to answer in your Jupyter Notebook files in this course; your general goal is to analyze your data using the methods you have learned about in this course and in this program and draw interesting conclusions. \n",
    "\n",
    "For Week 5, include concepts such as support vector machines, the kernel trick, and regularization for support vector machines. Complete your Jupyter Notebook homework by 11:59pm ET on Sunday. \n",
    "\n",
    "In Week 7, you will compile your findings from your Jupyter Notebook homework into your Milestone One assignment for grading. For full instructions and the rubric for Milestone One, refer to the following link. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following dataset, \"Video Review\", is a collection of information that was created based on reviewable video evidence that outlines the events that resulted in a concussion during punt players in the NFL 2016-2017 season. The target, Primary_Impact_Type, outlines if the concussion occurred from the impact of Helmet-to-Helmet, Helmet-to-Body, or Helmet-to-Ground."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy Video Review Dataset: 0.7586206896551724\n",
      "\n",
      "Classification Report (Video Review Dataset):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.86      0.77        14\n",
      "           1       1.00      1.00      1.00         1\n",
      "           2       0.80      0.62      0.70        13\n",
      "           3       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           0.76        29\n",
      "   macro avg       0.88      0.87      0.87        29\n",
      "weighted avg       0.77      0.76      0.75        29\n",
      "\n",
      "\n",
      "Confusion Matrix (Video Review Dataset):\n",
      " [[12  0  2  0]\n",
      " [ 0  1  0  0]\n",
      " [ 5  0  8  0]\n",
      " [ 0  0  0  1]]\n"
     ]
    }
   ],
   "source": [
    "#Video Review Dataset with support vector machines\n",
    "\n",
    "df_videoreview = pd.read_csv(\"video_review.csv\")\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "for col in df_videoreview.select_dtypes(include=['object']).columns:\n",
    "    df_videoreview[col] = label_encoder.fit_transform(df_videoreview[col].astype(str))\n",
    "\n",
    "\n",
    "target_column = 'Primary_Impact_Type'  \n",
    "X = df_videoreview.drop(columns=[target_column])\n",
    "y = df_videoreview[target_column]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "svm = SVC(kernel='rbf', decision_function_shape='ovr', class_weight='balanced', random_state=42)\n",
    "svm.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_train = svm.predict(X_train_scaled)\n",
    "\n",
    "print(\"Training Accuracy Video Review Dataset:\", accuracy_score(y_train, y_pred_train))\n",
    "print(\"\\nClassification Report (Video Review Dataset):\\n\", classification_report(y_train, y_pred_train))\n",
    "print(\"\\nConfusion Matrix (Video Review Dataset):\\n\", confusion_matrix(y_train, y_pred_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best C Video Review Dataset: 1\n",
      "Best cross-val accuracy Video Review Dataset: 0.4133333333333333\n",
      "Training set accuracy with best C Video Review Dataset: 0.7586206896551724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Video Review Dataset regularization for support vector machines\n",
    "\n",
    "param_grid = {'C': [0.01, 0.1, 1, 10, 100]}\n",
    "grid = GridSearchCV(SVC(kernel='rbf', class_weight='balanced', random_state=42), param_grid, cv=5)\n",
    "grid.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"Best C Video Review Dataset:\", grid.best_params_['C'])\n",
    "print(\"Best cross-val accuracy Video Review Dataset:\", grid.best_score_)\n",
    "\n",
    "train_accuracy = grid.best_estimator_.score(X_train_scaled, y_train)\n",
    "print(\"Training set accuracy with best C Video Review Dataset:\", train_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Video Review Dataset Training SVM with linear kernel:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.64      0.64        14\n",
      "           1       1.00      1.00      1.00         1\n",
      "           2       0.62      0.62      0.62        13\n",
      "           3       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           0.66        29\n",
      "   macro avg       0.81      0.81      0.81        29\n",
      "weighted avg       0.66      0.66      0.66        29\n",
      "\n",
      "\n",
      " Video Review Dataset Training SVM with poly kernel:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.64      0.78        14\n",
      "           1       1.00      1.00      1.00         1\n",
      "           2       0.72      1.00      0.84        13\n",
      "           3       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           0.83        29\n",
      "   macro avg       0.93      0.91      0.91        29\n",
      "weighted avg       0.88      0.83      0.82        29\n",
      "\n",
      "\n",
      " Video Review Dataset Training SVM with rbf kernel:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.86      0.77        14\n",
      "           1       1.00      1.00      1.00         1\n",
      "           2       0.80      0.62      0.70        13\n",
      "           3       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           0.76        29\n",
      "   macro avg       0.88      0.87      0.87        29\n",
      "weighted avg       0.77      0.76      0.75        29\n",
      "\n",
      "\n",
      " Video Review Dataset Training SVM with sigmoid kernel:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.43      0.50        14\n",
      "           1       0.14      1.00      0.25         1\n",
      "           2       0.60      0.46      0.52        13\n",
      "           3       0.50      1.00      0.67         1\n",
      "\n",
      "    accuracy                           0.48        29\n",
      "   macro avg       0.46      0.72      0.48        29\n",
      "weighted avg       0.58      0.48      0.51        29\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Video Review Dataset the kernel trick \n",
    "\n",
    "kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "\n",
    "for kernel in kernels:\n",
    "    print(f\"\\n Video Review Dataset Training SVM with {kernel} kernel:\")\n",
    "    svm = SVC(kernel=kernel, degree=3 if kernel == 'poly' else 3, class_weight='balanced', random_state=42)\n",
    "    svm.fit(X_train_scaled, y_train)\n",
    "    y_pred_train = svm.predict(X_train_scaled)\n",
    "    print(classification_report(y_train, y_pred_train))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next dataset, Injury Record, looks to determine the relationship between the playing surface and the injury and performance of NFL athletes. The Injury Record dataset accounts for 105 lower-limbs injuries that occurred over two seasons during the regular NFL season and provides information on the surface the game occurred on and the number of days the player missed due to injury (or how severe it was). The target in this case is surface which lists the type of surface (synethic or natural) the field was when the injury occurred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_injuryrecord = pd.read_csv(\"InjuryRecord.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy Injury Record Dataset: 0.6547619047619048\n",
      "\n",
      "Classification Report (Injury Record Dataset):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.64      0.63        39\n",
      "           1       0.68      0.67      0.67        45\n",
      "\n",
      "    accuracy                           0.65        84\n",
      "   macro avg       0.65      0.65      0.65        84\n",
      "weighted avg       0.66      0.65      0.66        84\n",
      "\n",
      "\n",
      "Confusion Matrix (Injury Record Dataset):\n",
      " [[25 14]\n",
      " [15 30]]\n"
     ]
    }
   ],
   "source": [
    "#Injury Record Dataset with support vector machines\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "for col in df_injuryrecord.select_dtypes(include=['object']).columns:\n",
    "    df_injuryrecord[col] = label_encoder.fit_transform(df_injuryrecord[col].astype(str))\n",
    "\n",
    "\n",
    "target_column = 'Surface'  \n",
    "X_injury = df_injuryrecord.drop(columns=[target_column])\n",
    "y_injury = df_injuryrecord[target_column]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_injury, y_injury, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "\n",
    "svm_injury = SVC(kernel='rbf', decision_function_shape='ovr', class_weight='balanced', random_state=42)\n",
    "svm_injury.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_train = svm_injury.predict(X_train_scaled)\n",
    "\n",
    "print(\"Training Accuracy Injury Record Dataset:\", accuracy_score(y_train, y_pred_train))\n",
    "print(\"\\nClassification Report (Injury Record Dataset):\\n\", classification_report(y_train, y_pred_train))\n",
    "print(\"\\nConfusion Matrix (Injury Record Dataset):\\n\", confusion_matrix(y_train, y_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best C Injury Record: 0.01\n",
      "Best cross-val accuracy Injury Record Dataset: 0.5110294117647058\n",
      "Training set accuracy with best C Injury Record Dataset: 0.5357142857142857\n"
     ]
    }
   ],
   "source": [
    "#Injury Record Dataset regularization for support vector machines\n",
    "param_grid_injury = {'C': [0.01, 0.1, 1, 10, 100]}\n",
    "grid_injury = GridSearchCV(SVC(kernel='rbf', class_weight='balanced', random_state=42), param_grid_injury, cv=5)\n",
    "grid_injury.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"Best C Injury Record:\", grid_injury.best_params_['C'])\n",
    "print(\"Best cross-val accuracy Injury Record Dataset:\", grid_injury.best_score_)\n",
    "\n",
    "train_accuracy_injury = grid_injury.best_estimator_.score(X_train_scaled, y_train)\n",
    "print(\"Training set accuracy with best C Injury Record Dataset:\", train_accuracy_injury)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Injury Record Dataset Training SVM with linear kernel:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.46      0.49        39\n",
      "           1       0.58      0.64      0.61        45\n",
      "\n",
      "    accuracy                           0.56        84\n",
      "   macro avg       0.55      0.55      0.55        84\n",
      "weighted avg       0.56      0.56      0.56        84\n",
      "\n",
      "\n",
      " Injury Record Dataset Training SVM with poly kernel:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.44      0.53        39\n",
      "           1       0.63      0.82      0.71        45\n",
      "\n",
      "    accuracy                           0.64        84\n",
      "   macro avg       0.65      0.63      0.62        84\n",
      "weighted avg       0.65      0.64      0.63        84\n",
      "\n",
      "\n",
      " Injury Record Dataset Training SVM with rbf kernel:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.64      0.63        39\n",
      "           1       0.68      0.67      0.67        45\n",
      "\n",
      "    accuracy                           0.65        84\n",
      "   macro avg       0.65      0.65      0.65        84\n",
      "weighted avg       0.66      0.65      0.66        84\n",
      "\n",
      "\n",
      " Injury Record Dataset Training SVM with sigmoid kernel:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.51      0.51        39\n",
      "           1       0.57      0.56      0.56        45\n",
      "\n",
      "    accuracy                           0.54        84\n",
      "   macro avg       0.53      0.53      0.53        84\n",
      "weighted avg       0.54      0.54      0.54        84\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Injury Record Dataset the kernel trick \n",
    "\n",
    "kernels_injury = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "\n",
    "for kernel in kernels_injury:\n",
    "    print(f\"\\n Injury Record Dataset Training SVM with {kernel} kernel:\")\n",
    "    svm_injury = SVC(kernel=kernel, degree=3 if kernel == 'poly' else 3, class_weight='balanced', random_state=42)\n",
    "    svm_injury.fit(X_train_scaled, y_train)\n",
    "    y_pred_train = svm_injury.predict(X_train_scaled)\n",
    "    print(classification_report(y_train, y_pred_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last dataset, Concussion, contains a list of concussion injuries that occurred in the National Football League from the year 2012 to 2014. The data includes features such as Position, Pre-Season Injury?, Week of Injury, Weeks Injured, Games Missed, Reported Injury Type, Average Playtime Before Injury, etc. The target in this case will be \"Reported Injury Type\" which will be limited to just concussions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy Concussion Dataset: 0.7846153846153846\n",
      "\n",
      "Classification Report (Concussion Dataset):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.75      0.85       209\n",
      "           1       0.47      0.92      0.63        51\n",
      "\n",
      "    accuracy                           0.78       260\n",
      "   macro avg       0.72      0.84      0.74       260\n",
      "weighted avg       0.88      0.78      0.81       260\n",
      "\n",
      "\n",
      "Confusion Matrix (Concussion Dataset):\n",
      " [[157  52]\n",
      " [  4  47]]\n"
     ]
    }
   ],
   "source": [
    "#Concussion Dataset with support vector machines\n",
    "\n",
    "df_concussion = pd.read_csv(\"Concussion Injuries 2012-2014 (1).csv\")\n",
    "df_clean_concussion = df_concussion.drop(columns=['ID', 'Player', 'Game', 'Date', 'Winning Team?', 'Unknown Injury?'])\n",
    "df_clean_concussion = df_clean_concussion.dropna()\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "for col in df_clean_concussion.select_dtypes(include=['object']).columns:\n",
    "    df_clean_concussion[col] = label_encoder.fit_transform(df_clean_concussion[col].astype(str))\n",
    "\n",
    "target_column = 'Reported Injury Type'  \n",
    "X_concussion = df_clean_concussion.drop(columns=[target_column])\n",
    "y_concussion = df_clean_concussion[target_column]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_concussion, y_concussion, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "\n",
    "\n",
    "svm_playlist = SVC(kernel='rbf', decision_function_shape='ovr', class_weight='balanced', random_state=42)\n",
    "svm_playlist.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_train = svm_playlist.predict(X_train_scaled)\n",
    "\n",
    "print(\"Training Accuracy Concussion Dataset:\", accuracy_score(y_train, y_pred_train))\n",
    "print(\"\\nClassification Report (Concussion Dataset):\\n\", classification_report(y_train, y_pred_train))\n",
    "print(\"\\nConfusion Matrix (Concussion Dataset):\\n\", confusion_matrix(y_train, y_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best C Concussion: 10\n",
      "Best cross-val accuracy Concussion Dataset: 0.7615384615384615\n",
      "Training set accuracy with best C Concussion Dataset: 0.95\n"
     ]
    }
   ],
   "source": [
    "#Concussion Dataset with regularization for support vector machines\n",
    "param_grid_playlist = {'C': [0.01, 0.1, 1, 10, 100]}\n",
    "grid_playlist= GridSearchCV(SVC(kernel='rbf', class_weight='balanced', random_state=42), param_grid_playlist, cv=5)\n",
    "grid_playlist.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"Best C Concussion:\", grid_playlist.best_params_['C'])\n",
    "print(\"Best cross-val accuracy Concussion Dataset:\", grid_playlist.best_score_)\n",
    "\n",
    "train_accuracy_injury = grid_playlist.best_estimator_.score(X_train_scaled, y_train)\n",
    "print(\"Training set accuracy with best C Concussion Dataset:\", train_accuracy_injury)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Concussion Dataset Training SVM with linear kernel:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.63      0.76       209\n",
      "           1       0.38      0.94      0.54        51\n",
      "\n",
      "    accuracy                           0.69       260\n",
      "   macro avg       0.68      0.78      0.65       260\n",
      "weighted avg       0.86      0.69      0.72       260\n",
      "\n",
      "\n",
      " Concussion Dataset Training SVM with poly kernel:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.89      0.93       209\n",
      "           1       0.66      0.90      0.76        51\n",
      "\n",
      "    accuracy                           0.89       260\n",
      "   macro avg       0.82      0.89      0.84       260\n",
      "weighted avg       0.91      0.89      0.89       260\n",
      "\n",
      "\n",
      " Concussion Dataset Training SVM with rbf kernel:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.75      0.85       209\n",
      "           1       0.47      0.92      0.63        51\n",
      "\n",
      "    accuracy                           0.78       260\n",
      "   macro avg       0.72      0.84      0.74       260\n",
      "weighted avg       0.88      0.78      0.81       260\n",
      "\n",
      "\n",
      " Concussion Dataset Training SVM with sigmoid kernel:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.64      0.75       209\n",
      "           1       0.34      0.76      0.47        51\n",
      "\n",
      "    accuracy                           0.67       260\n",
      "   macro avg       0.63      0.70      0.61       260\n",
      "weighted avg       0.80      0.67      0.70       260\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Concussion Dataset with the kernel trick \n",
    "\n",
    "kernels_playlist = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "\n",
    "for kernel in kernels_playlist:\n",
    "    print(f\"\\n Concussion Dataset Training SVM with {kernel} kernel:\")\n",
    "    svm_playlist = SVC(kernel=kernel, degree=3 if kernel == 'poly' else 3, class_weight='balanced', random_state=42)\n",
    "    svm_playlist.fit(X_train_scaled, y_train)\n",
    "    y_pred_train = svm_playlist.predict(X_train_scaled)\n",
    "    print(classification_report(y_train, y_pred_train))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
